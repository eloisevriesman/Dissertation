{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRE-PROCESSING OF THE DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the columns you want to include in the mean calculation along with 'PostID' for grouping\n",
    "selected_columns = df[['PostID','Toxicity', 'Rationality', 'Mutual Respect', 'Emotion']]\n",
    "# Group the selected columns by 'PostID' and calculate the mean for the numeric columns\n",
    "average_scores = selected_columns.groupby('PostID').mean()\n",
    "# Reset the index to make 'PostID' a column again\n",
    "average_scores.reset_index(inplace=True)\n",
    "new_df = average_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy calculation for weights distribution of the features\n",
    "def entropy(column):\n",
    "    _, counts = np.unique(column, return_counts=True)\n",
    "    probabilities = counts / counts.sum()\n",
    "    ent = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return ent\n",
    "\n",
    "# Calculate the entropy for each feature\n",
    "feature_entropies = {col: entropy(new_df[col]) for col in new_df.columns if col != 'PostID'}\n",
    "\n",
    "# Invert the entropies to get weights (features with lower entropy get higher weight)\n",
    "total_entropy = sum(feature_entropies.values())\n",
    "weights = {col: (total_entropy - entropy) / total_entropy for col, entropy in feature_entropies.items()}\n",
    "\n",
    "# Normalize the weights so they sum up to 1\n",
    "weight_sum = sum(weights.values())\n",
    "normalized_weights = {col: weight / weight_sum for col, weight in weights.items()}\n",
    "\n",
    "# Calculate the scores using the normalized weights\n",
    "def calculate_score(row, weights):\n",
    "    weighted_sum = sum(row[col] * weights[col] for col in weights if col in row.index)\n",
    "    return weighted_sum\n",
    "\n",
    "scores = new_df.apply(lambda row: calculate_score(row, normalized_weights), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['Classification_Score'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('conservative_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to create an innovative method for feature weight allocation based on the information entropy of each feature within the dataset. Our entropy calculation provides a quantitative measure of randomness or unpredictability in the data. The entropy for each feature extracted is measure of the inherent information content and variability.\n",
    "\n",
    "A higher entropy value corresponds to a feature with greater dispersion or variability in its values, suggesting a more significant potential for contributing to the predictive power of a model whether the post is combative or deliberative.\n",
    "\n",
    "To do this, we inverted the entropy values to prioritize features with lower entropy—hence presumed stability or consistency—and allocated higher weights to them. The underlying assumption is that features with lower variability (yet non-zero information content) may offer more reliable signals for prediction.\n",
    "\n",
    "Post-inversion, the weights were normalized across all features to ensure they summed to unity, maintaining a probabilistic interpretation. These normalized weights were then used in a weighted summation of feature values to compute a composite score. This score integrates the distinct contributions of each feature of the posts, adjusted for their respective entropy-derived importance, providing a nuanced approach to feature integration for predicting where it sits on the deliberativ-combative scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make it easier, I put all the code into a function so you can run it for each subreddit directory\n",
    "def process_subreddit_directory(folder_path):\n",
    "    # Function to parse comments and replies with CommentIDs\n",
    "    def parse_comments(comments, post_id, parent_id, depth, result, parent_counter=0):\n",
    "        for comment_index, comment in enumerate(comments):\n",
    "            # If it's a top-level comment, its ID is sth like post_1_0. Otherwise, it includes the parent's counter.\n",
    "            if depth == 1:  # Directly under post\n",
    "                comment_id = f\"{post_id}_{parent_counter + comment_index}\"\n",
    "            else:  # Nested comment/reply\n",
    "                comment_id = f\"{parent_id}_{comment_index + 1}\"\n",
    "\n",
    "            result.append({\n",
    "                'PostID': post_id,\n",
    "                'CommentID': comment_id,\n",
    "                'ParentID': parent_id,\n",
    "                'Author': comment['author'],\n",
    "                'Text': comment['body'],\n",
    "                'Depth': depth\n",
    "            })\n",
    "            if 'replies' in comment and comment['replies']:\n",
    "                # For replies, increment the parent counter for each new comment\n",
    "                parse_comments(comment['replies'], post_id, comment_id, depth + 1, result, 0)\n",
    "\n",
    "    # Function to process files in each subreddit directory\n",
    "    def process_reddit_posts(folder_path):\n",
    "        data = []\n",
    "        post_counter = 1  \n",
    "\n",
    "        for file_path in glob.glob(os.path.join(folder_path, '*.json')):\n",
    "            with open(file_path, 'r') as file:\n",
    "                post_data = json.load(file)\n",
    "                post_id = f\"post_{post_counter}\"  # e.g., post_1\n",
    "                post_counter += 1  \n",
    "\n",
    "                # Initially, add the post itself with a basic CommentID and no ParentID\n",
    "                data.append({\n",
    "                    'PostID': post_id,\n",
    "                    'CommentID': f\"{post_id}_0\",\n",
    "                    'ParentID': None,\n",
    "                    'Author': 'NONE',  # Placeholder\n",
    "                    'Text': post_data['title'],\n",
    "                    'Depth': 0\n",
    "                })\n",
    "\n",
    "                # Process comments, starting with depth=1\n",
    "                if 'comments' in post_data:\n",
    "                    parse_comments(post_data['comments'], post_id, f\"{post_id}_0\", 1, data)\n",
    "\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    # Function to modify mutual respect score\n",
    "    def modify_mutual_respect(row):\n",
    "        label = row['Mutual Respect']['label']\n",
    "        score = row['Mutual Respect']['score']\n",
    "\n",
    "        if label == 'NEUTRAL':\n",
    "            return score * 0.35\n",
    "        elif label == 'POLITE':\n",
    "            return score\n",
    "        elif label == 'SOMEWHAT_POLITE':\n",
    "            return score * 0.7\n",
    "        else:\n",
    "            return 1 - score\n",
    "\n",
    "    # Function to calculate entropy\n",
    "    def entropy(column):\n",
    "        _, counts = np.unique(column, return_counts=True)\n",
    "        probabilities = counts / counts.sum()\n",
    "        ent = -np.sum(probabilities * np.log2(probabilities))\n",
    "        return ent\n",
    "\n",
    "    # Function to calculate the scores using the normalized weights\n",
    "    def calculate_score(row, weights):\n",
    "        weighted_sum = sum(row[col] * weights[col] for col in weights if col in row.index)\n",
    "        return weighted_sum\n",
    "    \n",
    "    # Adding the emotion score of the text\n",
    "    def predict_emotion(text):\n",
    "        classifier = TextClassifier.load('en-sentiment')\n",
    "        sentence = Sentence(text)\n",
    "        classifier.predict(sentence)\n",
    "        # if the value is NEGATIVE then we take - value if the value is POSITIVE then we just keep that value\n",
    "        if sentence.labels[0].value == 'NEGATIVE':\n",
    "            return sentence.labels[0].score* -1\n",
    "        else:\n",
    "            return sentence.labels[0].score\n",
    "\n",
    "    # Load all the models and tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"NOVA-vision-language/polite_bert\")\n",
    "    respect_model = AutoModelForSequenceClassification.from_pretrained(\"NOVA-vision-language/polite_bert\")\n",
    "    classifier = pipeline('text-classification', model=respect_model, tokenizer=tokenizer)\n",
    "    detoxify_model = Detoxify('original')\n",
    "    sentiment_classifier = TextClassifier.load('en-sentiment')\n",
    "\n",
    "    # Process subreddit posts\n",
    "    df = process_reddit_posts(folder_path)\n",
    "\n",
    "    # Calculate mutual respect score\n",
    "    df['Mutual Respect'] = classifier(df['Text'].tolist())\n",
    "    df['Mutual Respect'] = df.apply(modify_mutual_respect, axis=1)\n",
    "    \n",
    "    # Calculate toxicity score\n",
    "    text_to_toxicity = df['Text'].astype(str).tolist()\n",
    "    detoxify_scores = detoxify_model.predict(text_to_toxicity)['toxicity']\n",
    "    df['Toxicity'] = np.sqrt(detoxify_scores)\n",
    "\n",
    "    # Calculate rationality score\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"d4data/bias-detection-model\")\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(\"d4data/bias-detection-model\")\n",
    "    classifier = pipeline('text-classification', model=model, tokenizer=tokenizer)\n",
    "    df['Rationality'] = classifier(df['Text'].tolist())\n",
    "    df['Rationality'] = df['Rationality'].apply(lambda x: x['score'] if x['label'] == 'Non-biased' else 1 - x['score'])\n",
    "\n",
    "    emotion = df['Text'].apply(predict_emotion)\n",
    "    scaled_emotion = (emotion+1)/2 # scale the emotion scores to be between 0 and 1\n",
    "    df['Emotion'] = scaled_emotion\n",
    "\n",
    "    # Select only the columns you want to include in the mean calculation along with 'PostID' for grouping\n",
    "    selected_columns = df[['PostID', 'Toxicity', 'Rationality', 'Mutual Respect', 'Emotion']]\n",
    "\n",
    "    # Group the selected columns by 'PostID' and calculate the mean for the numeric columns\n",
    "    average_scores = selected_columns.groupby('PostID').mean()\n",
    "\n",
    "    # Reset the index to make 'PostID' a column again\n",
    "    average_scores.reset_index(inplace=True)\n",
    "\n",
    "    # Calculate the entropy for each feature\n",
    "    feature_entropies = {col: entropy(average_scores[col]) for col in average_scores.columns if col != 'PostID'}\n",
    "\n",
    "    # Invert the entropies to get weights (features with lower entropy get higher weight)\n",
    "    total_entropy = sum(feature_entropies.values())\n",
    "    weights = {col: (total_entropy - entropy) / total_entropy for col, entropy in feature_entropies.items()}\n",
    "\n",
    "    # Normalize the weights so they sum up to 1\n",
    "    weight_sum = sum(weights.values())\n",
    "    normalized_weights = {col: weight / weight_sum for col, weight in weights.items()}\n",
    "\n",
    "    # Calculate the scores using the normalized weights\n",
    "    scores = average_scores.apply(lambda row: calculate_score(row, normalized_weights), axis=1)\n",
    "\n",
    "    # Add the scores to the dataframe\n",
    "    average_scores['Type'] = scores\n",
    "\n",
    "    return average_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit1_path = './Scripts/Political/Conservative_data'\n",
    "subreddit2_path = './Scripts/Political/AskALiberal_data'\n",
    "subreddit3_path = './Scripts/Political/NeutralPolitics_data'\n",
    "\n",
    "subreddit1_scores = process_subreddit_directory(subreddit1_path)\n",
    "subreddit2_scores = process_subreddit_directory(subreddit2_path)\n",
    "subreddit3_scores = process_subreddit_directory(subreddit3_path)\n",
    "\n",
    "create a dataframe with all the scores appended\n",
    "for each post id in the df add where it came from to the id, so you can differentiate \n",
    "between the posts from different subreddits\n",
    "subreddit1_scores['PostID'] = 'Conservative_' + subreddit1_scores['PostID']\n",
    "subreddit2_scores['PostID'] = 'Liberal_' + subreddit2_scores['PostID']\n",
    "subreddit3_scores['PostID'] = 'Neutral_' + subreddit3_scores['PostID']\n",
    "\n",
    "all_scores = pd.concat([subreddit1_scores, subreddit2_scores, subreddit3_scores])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
